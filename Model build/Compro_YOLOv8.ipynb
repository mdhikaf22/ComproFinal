{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition dengan YOLOv8 + ViT\n",
    "\n",
    "Notebook ini menggunakan:\n",
    "- **YOLOv8-face** untuk deteksi wajah (lebih cepat dari MTCNN)\n",
    "- **ViT (Vision Transformer)** untuk klasifikasi wajah\n",
    "\n",
    "## Perbandingan Speed\n",
    "| Detector | Speed | Accuracy |\n",
    "|----------|-------|----------|\n",
    "| MTCNN | ~2-3 FPS | Tinggi |\n",
    "| YOLOv8-face | ~15-30 FPS | Tinggi |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ultralytics torch torchvision transformers opencv-python pillow huggingface_hub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download YOLOv8-face Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "import os\n",
    "\n",
    "# Download YOLOv8-face model dari Hugging Face\n",
    "model_path = hf_hub_download(\n",
    "    repo_id=\"arnabdhar/YOLOv8-Face-Detection\", \n",
    "    filename=\"model.pt\",\n",
    "    local_dir=\".\"\n",
    ")\n",
    "\n",
    "# Rename untuk konsistensi\n",
    "if os.path.exists(\"model.pt\") and not os.path.exists(\"yolov8-face.pt\"):\n",
    "    os.rename(\"model.pt\", \"yolov8-face.pt\")\n",
    "    print(\"Model saved as: yolov8-face.pt\")\n",
    "else:\n",
    "    print(\"Model ready:\", model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "from torchvision import transforms\n",
    "from transformers import ViTForImageClassification\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import time\n",
    "\n",
    "# Check device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class names - sesuaikan dengan dataset training kamu\n",
    "CLASS_NAMES = [\n",
    "    \"akbar\", \"aprilianza\", \"bian\", \"fadhilah\", \"falah\",\n",
    "    \"iksan\", \"imelda\", \"rifqy\", \"yolanda\"\n",
    "]\n",
    "\n",
    "# Role mapping untuk authorization\n",
    "ROLE_MAPPING = {\n",
    "    \"iksan\": \"Aslab\",\n",
    "    \"akbar\": \"Aslab\",\n",
    "    \"aprilianza\": \"Aslab\",\n",
    "    \"bian\": \"Dosen\",\n",
    "    \"fadhilah\": \"Aslab\",\n",
    "    \"falah\": \"Aslab\",\n",
    "    \"imelda\": \"Aslab\",\n",
    "    \"rifqy\": \"Aslab\",\n",
    "    \"yolanda\": \"Aslab\",\n",
    "}\n",
    "\n",
    "# Thresholds\n",
    "CONFIDENCE_THRESHOLD = 0.5  # Minimum confidence untuk klasifikasi\n",
    "FACE_DETECTION_THRESHOLD = 0.35  # Minimum confidence untuk deteksi wajah\n",
    "\n",
    "# Model paths\n",
    "YOLO_MODEL_PATH = \"yolov8-face.pt\"  # YOLOv8-face model\n",
    "VIT_MODEL_PATH = \"../best_vit_mtcnn.pth\"  # ViT classification model\n",
    "\n",
    "print(f\"Classes: {CLASS_NAMES}\")\n",
    "print(f\"Number of classes: {len(CLASS_NAMES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load YOLOv8-face detector\n",
    "print(\"Loading YOLOv8-face...\")\n",
    "yolo = YOLO(YOLO_MODEL_PATH)\n",
    "print(\"YOLOv8-face loaded!\")\n",
    "\n",
    "# Warm up YOLO\n",
    "_ = yolo.predict(np.zeros((320, 320, 3), dtype=np.uint8), verbose=False)\n",
    "print(\"YOLOv8 warmed up!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ViT classifier\n",
    "print(\"Loading ViT classifier...\")\n",
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "    \"google/vit-base-patch16-224-in21k\",\n",
    "    num_labels=len(CLASS_NAMES),\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "# Load trained weights\n",
    "if os.path.exists(VIT_MODEL_PATH):\n",
    "    vit_model.load_state_dict(torch.load(VIT_MODEL_PATH, map_location=device))\n",
    "    print(f\"ViT weights loaded from {VIT_MODEL_PATH}\")\n",
    "else:\n",
    "    print(f\"WARNING: ViT weights not found at {VIT_MODEL_PATH}\")\n",
    "\n",
    "vit_model.to(device)\n",
    "vit_model.eval()\n",
    "print(\"ViT classifier ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform for ViT input\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_label(name):\n",
    "    \"\"\"Get full label with role and authorization status\"\"\"\n",
    "    name_lower = name.lower()\n",
    "    if name_lower in ROLE_MAPPING:\n",
    "        role = ROLE_MAPPING[name_lower]\n",
    "        return f\"{name.capitalize()} ({role})\", role, True\n",
    "    else:\n",
    "        return f\"{name} (Guest)\", \"Guest\", False\n",
    "\n",
    "\n",
    "def detect_faces_yolo(image):\n",
    "    \"\"\"Detect faces using YOLOv8-face\"\"\"\n",
    "    if isinstance(image, Image.Image):\n",
    "        img_np = np.array(image)\n",
    "    else:\n",
    "        img_np = image\n",
    "    \n",
    "    # Run detection\n",
    "    results = yolo.predict(img_np, verbose=False, conf=FACE_DETECTION_THRESHOLD, imgsz=480)\n",
    "    \n",
    "    faces = []\n",
    "    for r in results:\n",
    "        for box in r.boxes:\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "            conf = float(box.conf[0])\n",
    "            faces.append((x1, y1, x2, y2, conf))\n",
    "    \n",
    "    return faces\n",
    "\n",
    "\n",
    "def classify_face(face_image):\n",
    "    \"\"\"Classify face using ViT\"\"\"\n",
    "    if isinstance(face_image, np.ndarray):\n",
    "        face_image = Image.fromarray(face_image)\n",
    "    \n",
    "    face_tensor = transform(face_image).unsqueeze(0).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = vit_model(face_tensor).logits\n",
    "        probs = torch.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probs, 1)\n",
    "    \n",
    "    return predicted.item(), confidence.item()\n",
    "\n",
    "\n",
    "def process_image(image):\n",
    "    \"\"\"Process image: detect faces and classify each\"\"\"\n",
    "    if isinstance(image, np.ndarray):\n",
    "        if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(image)\n",
    "    else:\n",
    "        pil_image = image\n",
    "    \n",
    "    # Detect faces\n",
    "    faces = detect_faces_yolo(pil_image)\n",
    "    \n",
    "    results = []\n",
    "    img_w, img_h = pil_image.size\n",
    "    \n",
    "    for x1, y1, x2, y2, det_conf in faces:\n",
    "        # Add padding\n",
    "        w, h = x2 - x1, y2 - y1\n",
    "        pad = int(max(w, h) * 0.15)\n",
    "        x1 = max(0, x1 - pad)\n",
    "        y1 = max(0, y1 - pad)\n",
    "        x2 = min(img_w, x2 + pad)\n",
    "        y2 = min(img_h, y2 + pad)\n",
    "        \n",
    "        # Crop face\n",
    "        face = pil_image.crop((x1, y1, x2, y2))\n",
    "        \n",
    "        # Classify\n",
    "        predicted_idx, confidence = classify_face(face)\n",
    "        \n",
    "        if confidence >= CONFIDENCE_THRESHOLD:\n",
    "            name = CLASS_NAMES[predicted_idx]\n",
    "            full_label, role, authorized = get_full_label(name)\n",
    "        else:\n",
    "            name = \"Unknown\"\n",
    "            full_label = \"Unknown (Guest)\"\n",
    "            role = \"Guest\"\n",
    "            authorized = False\n",
    "        \n",
    "        results.append({\n",
    "            \"name\": name,\n",
    "            \"full_label\": full_label,\n",
    "            \"role\": role,\n",
    "            \"authorized\": authorized,\n",
    "            \"confidence\": confidence,\n",
    "            \"bbox\": (x1, y1, x2, y2),\n",
    "            \"detection_score\": det_conf\n",
    "        })\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test on Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(image_path):\n",
    "    \"\"\"Visualize detection results on an image\"\"\"\n",
    "    # Load image\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Could not load image: {image_path}\")\n",
    "        return\n",
    "    \n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Process\n",
    "    start_time = time.time()\n",
    "    results = process_image(img_rgb)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    # Draw results\n",
    "    for r in results:\n",
    "        x1, y1, x2, y2 = r['bbox']\n",
    "        color = (0, 255, 0) if r['authorized'] else (255, 0, 0)\n",
    "        \n",
    "        cv2.rectangle(img_rgb, (x1, y1), (x2, y2), color, 2)\n",
    "        \n",
    "        label = f\"{r['full_label']} ({r['confidence']*100:.1f}%)\"\n",
    "        cv2.putText(img_rgb, label, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img_rgb)\n",
    "    plt.title(f\"Detected {len(results)} face(s) in {elapsed*1000:.1f}ms ({1/elapsed:.1f} FPS)\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test dengan gambar (ganti path sesuai kebutuhan)\n",
    "# results = visualize_detection(\"test_image.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Real-time Webcam Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_webcam_detection(duration=30):\n",
    "    \"\"\"\n",
    "    Run real-time face detection on webcam\n",
    "    \n",
    "    Args:\n",
    "        duration: How long to run (seconds). Set to 0 for infinite.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    # Set resolution\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(\"Webcam started. Press 'q' to quit.\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    frame_count = 0\n",
    "    start_time = time.time()\n",
    "    fps_list = []\n",
    "    \n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_start = time.time()\n",
    "            \n",
    "            # Convert to RGB\n",
    "            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            # Process\n",
    "            results = process_image(rgb_frame)\n",
    "            \n",
    "            # Draw results\n",
    "            for r in results:\n",
    "                x1, y1, x2, y2 = r['bbox']\n",
    "                color = (0, 255, 0) if r['authorized'] else (0, 0, 255)\n",
    "                \n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)\n",
    "                \n",
    "                label = f\"{r['full_label']} ({r['confidence']*100:.1f}%)\"\n",
    "                \n",
    "                # Background for text\n",
    "                (tw, th), _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)\n",
    "                cv2.rectangle(frame, (x1, y1-25), (x1+tw+10, y1), color, -1)\n",
    "                cv2.putText(frame, label, (x1+5, y1-8), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 2)\n",
    "            \n",
    "            # Calculate FPS\n",
    "            frame_time = time.time() - frame_start\n",
    "            fps = 1 / frame_time if frame_time > 0 else 0\n",
    "            fps_list.append(fps)\n",
    "            avg_fps = np.mean(fps_list[-30:])  # Average of last 30 frames\n",
    "            \n",
    "            # Draw FPS\n",
    "            cv2.putText(frame, f\"FPS: {avg_fps:.1f}\", (10, 30), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            cv2.putText(frame, f\"Faces: {len(results)}\", (10, 60), \n",
    "                       cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "            \n",
    "            # Display\n",
    "            cv2.imshow('YOLOv8 + ViT Face Recognition', frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            \n",
    "            # Check for quit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "            # Check duration\n",
    "            if duration > 0 and (time.time() - start_time) > duration:\n",
    "                break\n",
    "                \n",
    "    finally:\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        \n",
    "        # Print stats\n",
    "        total_time = time.time() - start_time\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "        print(f\"Total frames: {frame_count}\")\n",
    "        print(f\"Total time: {total_time:.1f}s\")\n",
    "        print(f\"Average FPS: {frame_count/total_time:.1f}\")\n",
    "        print(f\"Min FPS: {min(fps_list):.1f}\")\n",
    "        print(f\"Max FPS: {max(fps_list):.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run webcam detection for 30 seconds\n",
    "# Press 'q' to quit early\n",
    "run_webcam_detection(duration=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Benchmark: YOLO vs MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_detection(num_frames=100):\n",
    "    \"\"\"Benchmark YOLOv8-face detection speed\"\"\"\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(\"Error: Could not open webcam\")\n",
    "        return\n",
    "    \n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    \n",
    "    print(f\"Benchmarking {num_frames} frames...\")\n",
    "    \n",
    "    detection_times = []\n",
    "    classification_times = []\n",
    "    total_times = []\n",
    "    \n",
    "    for i in range(num_frames):\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        pil_image = Image.fromarray(rgb_frame)\n",
    "        \n",
    "        # Time detection\n",
    "        t1 = time.time()\n",
    "        faces = detect_faces_yolo(pil_image)\n",
    "        t2 = time.time()\n",
    "        detection_times.append(t2 - t1)\n",
    "        \n",
    "        # Time classification (if faces found)\n",
    "        if faces:\n",
    "            x1, y1, x2, y2, _ = faces[0]\n",
    "            face = pil_image.crop((x1, y1, x2, y2))\n",
    "            t3 = time.time()\n",
    "            classify_face(face)\n",
    "            t4 = time.time()\n",
    "            classification_times.append(t4 - t3)\n",
    "        \n",
    "        total_times.append(time.time() - t1)\n",
    "        \n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"  Processed {i+1}/{num_frames} frames...\")\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    # Print results\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(\"BENCHMARK RESULTS\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"\\nYOLOv8-face Detection:\")\n",
    "    print(f\"  Average: {np.mean(detection_times)*1000:.1f}ms\")\n",
    "    print(f\"  Min: {np.min(detection_times)*1000:.1f}ms\")\n",
    "    print(f\"  Max: {np.max(detection_times)*1000:.1f}ms\")\n",
    "    \n",
    "    if classification_times:\n",
    "        print(f\"\\nViT Classification:\")\n",
    "        print(f\"  Average: {np.mean(classification_times)*1000:.1f}ms\")\n",
    "        print(f\"  Min: {np.min(classification_times)*1000:.1f}ms\")\n",
    "        print(f\"  Max: {np.max(classification_times)*1000:.1f}ms\")\n",
    "    \n",
    "    print(f\"\\nTotal Pipeline:\")\n",
    "    print(f\"  Average: {np.mean(total_times)*1000:.1f}ms\")\n",
    "    print(f\"  Estimated FPS: {1/np.mean(total_times):.1f}\")\n",
    "\n",
    "# Run benchmark\n",
    "# benchmark_detection(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Save Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "config = {\n",
    "    \"detector\": \"YOLOv8-face\",\n",
    "    \"classifier\": \"ViT-base-patch16-224\",\n",
    "    \"class_names\": CLASS_NAMES,\n",
    "    \"role_mapping\": ROLE_MAPPING,\n",
    "    \"confidence_threshold\": CONFIDENCE_THRESHOLD,\n",
    "    \"face_detection_threshold\": FACE_DETECTION_THRESHOLD,\n",
    "    \"yolo_model_path\": YOLO_MODEL_PATH,\n",
    "    \"vit_model_path\": VIT_MODEL_PATH\n",
    "}\n",
    "\n",
    "with open(\"yolov8_config.json\", \"w\") as f:\n",
    "    json.dump(config, f, indent=2)\n",
    "\n",
    "print(\"Configuration saved to yolov8_config.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
